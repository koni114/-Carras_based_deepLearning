<Chapter07 딥러닝을 위한 도구>
여기서 알 수 있는 것.
- 케라스의 함수형 API 사용하여 그래프 구조를 띤 모델 만들기
- 하나의 층을 다른 입력에 같이 사용
- 케라스 모델을 파이썬 함수처럼 사용
- 케라스 callback
- 텐서보드 사용
- 배치 정규화, 잔차 연결, 하이퍼파라미터 최적화, 모델 앙상블을 통한 모범 사례

7.1 Sequential 모델을 넘어서: 케라스의 함수형 API

Sequential 모델은 네트워크 입력과 출력이 하나라고 가정.
but, 이런 가정이 맞지 않는 경우도 많음.
ex) 개별 입력이 여러 개 필요하거나 출력이 여러 개 필요
     층을 차례대로 쌓지 않고 층 사이를 연결하여 그래프처럼 만드는 경우.

예시 1   
중고 의류 시장 가격을 예측하는 딥러닝 모델(입력 값이 여러 개)
input data -> 메타데이터(의류 브랜드, 연도 등), 사용자가 제공하는 text 설명, 제품 사진
각 데이터를 완전 연결 모듈, RNN 모듈, 컨브넷 모듈에 연결하여 가중 평균을 한다!
-> 이를 다중 입력 모델이라고 함.

예시 2
소설이나 짧은 글이 있을 때 자동으로 장르별 구분
글을 쓴 대략의 시대 예측
2개의 모델을 따로 훈련할 수 있지만 이 속성들은 통계적으로 독립적이지 않기 때문에 
동시에 장르와 시대를 함께 예측하도록 해야 더 좋은 모델을 만들 수 있음.
why ? 두 개의 예측 값은 상관관계 때문에 소설 시대를 알면, 장르의 공간에서 정확하고 풍부한
         표현을 학습하는데 도움을 줌.

최근 개발된 신경망 구조는 선형적이지 않은 network topology가 필요
ex) 인셉션 모듈을 사용하는 인셉션 개열의 네트워크
     -> 이 모듈에서 입력은 나란히 놓인 여러개의 합성곱 층을 거쳐 하나의 텐서로 출력이 합쳐짐

** network topology(위상 수학(?))
비순환 유향 그래프 같은 네트워크 구조

최근에는 모델에 잔차 연결을 추가하는 경향도 있음
ResNet 계열의 네트워크들이 이런 방식을 사용하기 시작.
텐서를 상위 층의 출력 텐서에 더해서 아래층의 표현이 네트워크 위쪽으로 흘러갈 수 있도록 함(아래 층 값이 윗 층의 값에 영향을 미치는 구조)
-> 하위 층에서 학습된 정보가 데이터 처리 과정에서 손실되는 것을 방지

결과적으로 다중 입력 모델, 다중 출력 모델, 그래프 구조를 띤 모델이 필요하지만
케라스의 Sequential 클래스를 사용해서는 만들지 못함.

** 7.1.1 함수형 API 소개
함수처럼 층을 사용하여 텐서를 입력받고 출력함

input_tensor = Input(shape = (32, )) 
dense = layers.Dense(32, activation = 'relu')
output_tensor = dense(input_tensor)

Model 객체를 사용한 컴파일, 훈련, 평가 API는 Sequential 클래스와 같음

** 7.1.2 다중 입력 모델
함수형 API는 다중 입력 모델을 만드는 데 사용할 수 있음
서로 다른 입력 가지를 합치기 위해 여러 텐서를 연결할 수 있는 층을 사용
ex) 텐서를 더하거나, 이어 붙이는 방법.
keras.layers.add / keras.layers.concatenate 등

* 간단한 다중 입력 모델
ex) 질문 응답 모델

참고 텍스트 -> Embedding -> LSTM
				-> Concatenate -> Dense -> 응답
질문           -> Embedding -> LSTM 

* Embedding
범주형 자료를 연속형 벡터 형태로 변환시키는 것을 embedding이라고 함.

입력이 2개인 모델의 훈련 방법은 2가지
- 넘파이 배열의 리스트를 주입
ex) model.fit({[text, question], answers, epochs = 10, batch_size = 128)

- 입력 이름과 넘파이 배열로 이루어진 딕셔너리를 모델의 입력으로 주입할 수 있음
ex) model.fit({'text' : text, 'question': question}, answers, epochs=10, batch_size = 128)

7.1.3 다중 출력 모델
함수형 API를 사용하여 다중 출력 모델을 만들 수 있음
데이터에 있는 여러 속성을 동시에 예측하는 네트워크
ex) 소셜 미디어에서 익명 사용자의 포스트를 입력으로 받아 그 사람의 나이,
     성별, 소득 수준 등을 예측

소셜 미디어 포스트 -> 1D 컨브넷  -> Dense  -> 나이
			       -> Dense  -> 소득
  			       -> Dense  -> 성별
 

네트워크 출력마다 다른 손실함수를 지정해 주어야 함 
ex) 나이 예측은 스칼라 회귀 문제 이지만, 성별 예측은 이진 클래스 문제라 훈련 방식이 다름
경사 하강법은 하나의 스칼라 값을 최소화하기 때문에 모델을 훈련하려면 이 손실들을
하나의 값으로 합쳐야 함
-> 가장 간단한 방법은 모두 더하는 방법

케라스에서는 compile method에 리스트나 딕셔너리를 사용하여
출력마다 다른 손실을 지정할 수 있음.
-> 계산된 손실 값은 전체 손실 하나로 더해지고 훈련 과정을 통해 최소화 됨

model.compile(optimizer = 'rmsprop',
	        loss = ['mse', 'categorical_crossentropy', 'binary_crossentropy'])

손실 값이 많이 불균형하면 모델이 개별 손실이 가장 큰 작업에 치우쳐 
표현을 최적화함 -> 다른 작업들은 손해를 입을 수 있음

손실 값이 최종 손실에 기여하는 수준을 지정할 수 있음
ex) 손실 값의 스케일이 다를 때 유용
     나이 회귀 작업에 사용되는 MSE 손실은 3~5사이를 가지고 
     성별 분류 작업에 사용되는 크로스엔트로피 손실은 0.1 정도로 낮을 때,

    각각 가중치를 통해 균형을 맞춰 줄 수 있음!

model.compile(optimizer = 'rmsprop',
	        loss = ['mse', 'categorical_crossentropy', 'binary_crossentropy'],
	        loss_weights = {'age' = 0.25, 'income' : 1., 'gender' : 10.} 
)

7.1.4 층으로 구성된 비순환 유향 그래프
함수형 API를 사용하면, 내부 토폴로지가 복잡한 네트워크도 만들 수 있음
케라스의 신경망은 층으로 구성된 어떤 비순환 유향 그래프도 만들 수 있음

** 인셉션 모듈(Inception Module)
인셉션은 합성곱 신경망에서 인기 있는 네트워크 구조.
네트워크 안의 네트워크 구조에서 영감을 받아 2013~2014년에 크리스티안 세게디와 그의 구글 동료들이 만듬.
가장 기본적인 인셉션 모듈 형태는 3~4개의 가지를 가짐
1X1 합성곱으로 시작해서 3X3 합성곱이 뒤따르고 마지막에 전체 출력 특성이 합쳐짐
이런 구성은 네트워크가 따로따로 공간 특성과 채널 방향의 특성을 학습하도록 도움
(각 네트워크 채널마다 특유의 특성을 학습한다는 의미)
-> 한꺼번에 학습하는 것 보다 효과가 높음












 




















